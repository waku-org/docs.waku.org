"use strict";(self.webpackChunkwaku_guide=self.webpackChunkwaku_guide||[]).push([[8173],{3905:(e,t,a)=>{a.d(t,{Zo:()=>h,kt:()=>c});var n=a(67294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function s(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?s(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},s=Object.keys(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var l=n.createContext({}),p=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},h=function(e){var t=p(e.components);return n.createElement(l.Provider,{value:t},e.children)},d="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,s=e.originalType,l=e.parentName,h=o(e,["components","mdxType","originalType","parentName"]),d=p(a),u=i,c=d["".concat(l,".").concat(u)]||d[u]||m[u]||s;return a?n.createElement(c,r(r({ref:t},h),{},{components:a})):n.createElement(c,r({ref:t},h))}));function c(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var s=a.length,r=new Array(s);r[0]=u;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o[d]="string"==typeof e?e:i,r[1]=o;for(var p=2;p<s;p++)r[p]=a[p];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},71899:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>s,metadata:()=>o,toc:()=>p});var n=a(87462),i=(a(67294),a(3905));const s={title:"Message Propagation Times With Waku-RLN"},r=void 0,o={unversionedId:"research/research-and-studies/message-propagation",id:"research/research-and-studies/message-propagation",title:"Message Propagation Times With Waku-RLN",description:"TLDR: We present the results of 1000 nwaku nodes running rln using different message sizes, in a real network with bandwidth limitations and network delays. The goal is to study the message propagation delay distribution, and how it's affected by i) rln and ii) message size in a real environment. We observe that for messages of 10kB the average end-to-end propagation delay is 508 ms. We can also observe that the message propagation delays are severely affected when increasing the message size, which indicates that it is not a good idea to use waku for messages of eg. 500kB. See simulation parameters.",source:"@site/docs/research/research-and-studies/message-propagation.md",sourceDirName:"research/research-and-studies",slug:"/research/research-and-studies/message-propagation",permalink:"/research/research-and-studies/message-propagation",draft:!1,editUrl:"https://github.com/waku-org/docs.waku.org/tree/develop/docs/research/research-and-studies/message-propagation.md",tags:[],version:"current",lastUpdatedAt:1708340432,formattedLastUpdatedAt:"19 Feb 2024",frontMatter:{title:"Message Propagation Times With Waku-RLN"},sidebar:"research",previous:{title:"Maximum Bandwidth for Global Adoption",permalink:"/research/research-and-studies/maximum-bandwidth"},next:{title:"RLN Key Benchmarks",permalink:"/research/research-and-studies/rln-key-benchmarks"}},l={},p=[{value:"Introduction",id:"introduction",level:2},{value:"Theory",id:"theory",level:2},{value:"Simulations",id:"simulations",level:2},{value:"Results",id:"results",level:2}],h={toc:p},d="wrapper";function m(e){let{components:t,...s}=e;return(0,i.kt)(d,(0,n.Z)({},h,s,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"TLDR"),": We present the results of 1000 ",(0,i.kt)("inlineCode",{parentName:"p"},"nwaku")," nodes running ",(0,i.kt)("inlineCode",{parentName:"p"},"rln")," using different message sizes, in a real network with bandwidth limitations and network delays. The goal is to study the message propagation delay distribution, and how it's affected by i) rln and ii) message size in a real environment. We observe that for messages of ",(0,i.kt)("inlineCode",{parentName:"p"},"10kB")," the average end-to-end propagation delay is ",(0,i.kt)("inlineCode",{parentName:"p"},"508 ms"),". We can also observe that the message propagation delays are severely affected when increasing the message size, which indicates that it is not a good idea to use waku for messages of eg. ",(0,i.kt)("inlineCode",{parentName:"p"},"500kB"),". See simulation parameters."),(0,i.kt)("h2",{id:"introduction"},"Introduction"),(0,i.kt)("p",null,"Waku uses ",(0,i.kt)("a",{parentName:"p",href:"https://rfc.vac.dev/spec/11/"},"relay")," as a routing protocol, which is an adaptation of ",(0,i.kt)("a",{parentName:"p",href:"https://arxiv.org/pdf/2007.02754.pdf"},"gossipsub"),". It routes messages following a publisher/subscriber architecture, where nodes can publish messages or subscribe to topics. If message ",(0,i.kt)("inlineCode",{parentName:"p"},"m")," is published to topic ",(0,i.kt)("inlineCode",{parentName:"p"},"t"),", all ",(0,i.kt)("inlineCode",{parentName:"p"},"i")," nodes ",(0,i.kt)("inlineCode",{parentName:"p"},"n_1...n_i")," subscribed to ",(0,i.kt)("inlineCode",{parentName:"p"},"t")," will get ",(0,i.kt)("inlineCode",{parentName:"p"},"m"),". The ",(0,i.kt)("inlineCode",{parentName:"p"},"relay")," protocol ensures that every node gets the messages of the topics it is subscribed to."),(0,i.kt)("p",null,"However, since ",(0,i.kt)("inlineCode",{parentName:"p"},"relay")," works in a decentralized manner, all nodes contribute to the gossiping of a message, until it has successfully reached all the interested nodes (subscribed to it). This means that a message can travel multiple hops until it reaches all nodes. The amount of hops determines the ",(0,i.kt)("strong",{parentName:"p"},"message propagation time"),", which is measured as the ",(0,i.kt)("strong",{parentName:"p"},"time difference of when the node published the message and when another node received"),"."),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"This issue aims to go from theory to practice, by i) understanding message propagation times in theory and ii) presenting nwaku simulation results in an end-to-end setup with rln, with real message propagation times"),"."),(0,i.kt)("h2",{id:"theory"},"Theory"),(0,i.kt)("p",null,"Let's start with ",(0,i.kt)("strong",{parentName:"p"},"message propagation times in theory"),". On a high level, it depends on:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"The gossipsub ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/libp2p/specs/blob/master/pubsub/gossipsub/gossipsub-v1.0.md#parameters"},"configuration"),", being ",(0,i.kt)("inlineCode",{parentName:"li"},"D")," one of the most important parameters. This sets the hops that a message will travel to reach all nodes. Higher ",(0,i.kt)("inlineCode",{parentName:"li"},"D"),", less hops, less delay. Note that a higher ",(0,i.kt)("inlineCode",{parentName:"li"},"D")," implies more bandwidth consumption."),(0,i.kt)("li",{parentName:"ul"},"The node. Different nodes will see different propagation times, because a message can travel different paths. A node connected directly to the publisher (1 hop) will see lower propagation times than other nodes further away."),(0,i.kt)("li",{parentName:"ul"},"Individual propagation times. Since a message can travel multiple hops to reach its destination, each hop adds a contribution to the overall message propagation time. This individual propagation time depends on the characteristics on the nodes involved in the connections.")),(0,i.kt)("p",null,"In a D-regular graph, like the one formed by waku nodes around a topic, the maximum amount of hops that a message can travel to reach all nodes can be calculated as ",(0,i.kt)("inlineCode",{parentName:"p"},"ceil(log(total_nodes)/log(D))"),". For example, with log(1000)/log(6) = 3.85 = 4. So in a network with 1000 nodes and ",(0,i.kt)("inlineCode",{parentName:"p"},"D=6"),", no matter which node publishes the message, in 4 hops it will reach all the nodes."),(0,i.kt)("p",null,"Notice the ",(0,i.kt)("strong",{parentName:"p"},'"worst case"')," since some nodes might be directly connected to the publisher, so they will get the message in just 1 hop."),(0,i.kt)("p",null,"But how long does it take to jump each hop? It depends on:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"The latency between nodes. Can be measured as the time to respond to a ping."),(0,i.kt)("li",{parentName:"ul"},"The size of the messages. The bigger the message, the more time it takes to transmit."),(0,i.kt)("li",{parentName:"ul"},"Nodes bandwidth. Sender upload bandwidth and receiver download bandwidth. More important when using big message sizes."),(0,i.kt)("li",{parentName:"ul"},"Message validation time. When each node receives a message, it applies some validation to decide if the message is further gossiped or not. In the case of waku, this is RLN (",(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/2207.00116.pdf"},"paper"),", ",(0,i.kt)("a",{parentName:"li",href:"https://rfc.vac.dev/spec/32/"},"rfc"),")")),(0,i.kt)("p",null,"Assuming a message ",(0,i.kt)("inlineCode",{parentName:"p"},"m")," that travels 4 hops from node ",(0,i.kt)("inlineCode",{parentName:"p"},"n1")," (publisher) to ",(0,i.kt)("inlineCode",{parentName:"p"},"n5")," (subscriber) we can calculate the message propagation time ",(0,i.kt)("inlineCode",{parentName:"p"},"mpt=ipt_1+ipt_2+ipt_3+ipt_4")," where ",(0,i.kt)("inlineCode",{parentName:"p"},"ipt")," is the individual propagation time between each node in the chain."),(0,i.kt)("p",null,"However, specific message propagation times are useless, we need average times under specific conditions. And ",(0,i.kt)("strong",{parentName:"p"},"for this, we need simulations"),"."),(0,i.kt)("h2",{id:"simulations"},"Simulations"),(0,i.kt)("p",null,"Using ",(0,i.kt)("a",{parentName:"p",href:"https://shadow.github.io/docs/guide/shadow.html"},"shadow")," simulator, we have developed a ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/waku-org/research/tree/master/rln-delay-simulations"},"tool")," that allows to simulate message propagation delays of ",(0,i.kt)("inlineCode",{parentName:"p"},"nwaku")," (using a slightly modified ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/waku-org/nwaku/compare/master...simulations"},"branch"),", mainly to instrument it with tools to measure the times + starting from an already connected mesh. Thanks ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/menduist"},"@Menduist")," for the help. Note that running this simulation requires a significant amount of resources, done with 256 GB of RAM."),(0,i.kt)("p",null,"The configuration of the simulation is (see ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/waku-org/research/blob/master/rln-delay-simulations/shadow.yaml"},"config"),"):"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"latency=100ms"),". Average latency in our current waku network. Thanks ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/vpavlin"},"@vpavlin")," for the measurements. See ",(0,i.kt)("a",{parentName:"li",href:"https://grafana.infra.status.im/d/b819dbfe-acb6-4086-8736-578ca148d7cd/waku-networkmonitor-v2?orgId=1&refresh=30s&viewPanel=12"},"this")," for live data."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"down_bandwidth=83Mbps"),", ",(0,i.kt)("inlineCode",{parentName:"li"},"up_bandwidth=38Mbps"),". As shown in ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/waku-org/research/issues/31"},"Table 2")," that's the worldwide median speed."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"D=6"),", which is the current ",(0,i.kt)("inlineCode",{parentName:"li"},"nwaku")," ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/waku-org/nwaku/blob/v0.21.0/waku/waku_relay/protocol.nim#L73-L78"},"configuration"),"."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"nodes=1000"),". Amount of nodes used in the simulation"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"nwaku")," was used with a minor ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/waku-org/nwaku/compare/master...simulations"},"modification")),(0,i.kt)("li",{parentName:"ul"},"A total of ",(0,i.kt)("inlineCode",{parentName:"li"},"10")," messages were published, that led to ",(0,i.kt)("inlineCode",{parentName:"li"},"9990")," received messages."),(0,i.kt)("li",{parentName:"ul"},"Since ",(0,i.kt)("inlineCode",{parentName:"li"},"shadow")," ",(0,i.kt)("strong",{parentName:"li"},"doesn't take into account CPU times")," (",(0,i.kt)("a",{parentName:"li",href:"https://github.com/shadow/shadow/discussions/1675#discussioncomment-7342812"},"by now"),"), we simulate it with ",(0,i.kt)("inlineCode",{parentName:"li"},"sleepAsync")," as per ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/waku-org/research/issues/23"},"https://github.com/waku-org/research/issues/23")," findings. ",(0,i.kt)("inlineCode",{parentName:"li"},"0.012 seconds")," for proof verification and ",(0,i.kt)("inlineCode",{parentName:"li"},"0.15 seconds")," for proof generation.")),(0,i.kt)("h2",{id:"results"},"Results"),(0,i.kt)("p",null,"The following figure shows the ",(0,i.kt)("strong",{parentName:"p"},"message propagation time with real simulations"),", showing the distribution in a network with the above configuration with three different message sizes: ",(0,i.kt)("inlineCode",{parentName:"p"},"10kB"),", ",(0,i.kt)("inlineCode",{parentName:"p"},"100kB"),", ",(0,i.kt)("inlineCode",{parentName:"p"},"500kB"),". Note that the whiskers indicate the best/worst values and the box contains P25 to P75 values. Average ",(0,i.kt)("inlineCode",{parentName:"p"},"mu")," and P95 are also shown. Raw data ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/waku-org/research/tree/master/rln-delay-simulations/raw"},"here"),"."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"message-latency-distribution",src:a(83800).Z,width:"2400",height:"1800"})),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Important note"),". The first messages sent in the simulations are omitted, since they show an abnormal propagation delay that doesn't reflect reality. This is due to how flow control works in TCP, where right after connection, the sender node has no idea of the \"bandwidth\" of the receiver node, so it will start sending packages at a lower rate. This translates into high transmission times, and it's more pronounced when dealing with big message sizes."),(0,i.kt)("p",null,"In other words, in a 100Mpbs link, 100Mbits won't be sent in 1 second, or at least not a the beginning, when the node is slowly increasing the rate until based on ACK/NACK ratio. For more information about this, this is explained in ",(0,i.kt)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=vb_wjh_nAmo"},"here"),"."),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Conclusions:")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Using small messages ",(0,i.kt)("inlineCode",{parentName:"li"},"10kB")," the ",(0,i.kt)("strong",{parentName:"li"},"average propagation delay is ",(0,i.kt)("inlineCode",{parentName:"strong"},"508 ms")),", quite reasonable for applications using waku. The variance is acceptable, with 95% of the messages arriving in ",(0,i.kt)("inlineCode",{parentName:"li"},"<627 ms"),"."),(0,i.kt)("li",{parentName:"ul"},"When using a size of ",(0,i.kt)("inlineCode",{parentName:"li"},"10kB")," we can see that the best case propagation delay is ",(0,i.kt)("inlineCode",{parentName:"li"},"263 ms"),". This corresponds to the nodes that are just 1 hop from the publisher. The proof generation time ",(0,i.kt)("inlineCode",{parentName:"li"},"0.15 seconds")," affects the most, where the rest is the inter-node latency and the transmission of the message itself."),(0,i.kt)("li",{parentName:"ul"},"We can see that the ",(0,i.kt)("strong",{parentName:"li"},"message propagation delay increases with big messages"),", ",(0,i.kt)("inlineCode",{parentName:"li"},"100kB")," and ",(0,i.kt)("inlineCode",{parentName:"li"},"500kB"),". So its ",(0,i.kt)("strong",{parentName:"li"},"probably not a good idea to use waku for such big messages"),". Note that these simulations had 1000 nodes, so if we scale it to 10000 or beyond, propagation times would be worse."),(0,i.kt)("li",{parentName:"ul"},"Best case propagation time (lower part of the whisker) is quite similar in all cases. This is because it corresponds to the node that is just 1 hop away from the publisher.")),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Future work"),":"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Current waku ",(0,i.kt)("inlineCode",{parentName:"li"},"D")," ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/waku-org/nwaku/blob/v0.21.0/waku/waku_relay/protocol.nim#L73-L78"},"values")," (average of 6 ranging from 4 to 12) have a huge impact on the bandwidth that a node consumes. Are we willing to lower D in order to reduce bandwidth but increase message propagation times?"),(0,i.kt)("li",{parentName:"ul"},"Since ",(0,i.kt)("inlineCode",{parentName:"li"},"shadow")," doesn't take CPU time into account, it's currently simulated for rln, which should be the biggest bottleneck. Once ",(0,i.kt)("inlineCode",{parentName:"li"},"shadow")," has ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/shadow/shadow/discussions/1675#discussioncomment-7342812"},"this feature")," times would be more accurate.")))}m.isMDXComponent=!0},83800:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/message-latencies-distribution-3371680debde538ccb37052f55074c49.png"}}]);